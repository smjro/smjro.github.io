---
layout: post
title: 分類問題〜パーセプトロン編〜
categories:
- programming
tags:
- classification
- python
- perceptron
prism: true
---
irisデータをパーセプトロンを用いて分類します。

#### はじめに
---
最近、Deep learningの話題を目にすることが増えてきました。
しかし、Deep learningを本格的に利用しようとすると、
データ収集やマシンスペックが必要となります。
実際、Deep learningを適用しようとしているタスクは
以前からあるロジスティック回帰や、SVM（サポートベクターマシン）、
ランダムフォレスト等で事足りることがあるので、
そのへんも抑えておこうと思います。

まずは、Deep learningや機械学習の基本となるパーセプトロンを使って
irisデータを分類します。

また、以下では

● scikit-learn

を使用します。

#### データの前処理
---
パーセプトロンモデルをトレーニングする前に、irisデータをトレーニングデータと
テストデータに分けたり、標準化を行う。

まずは、scikit-learnのdatasetからirisデータを読み込む。また、可視化するために、
ここではirisデータの特徴量のうち２つだけを使用する。使用する特徴量は「がく片の長さ」と
「花びらの長さ」とし、特徴量をX, クラスラベルをyに代入する。

```python
>>> from sklearn import datasets
>>> import numpy as np
>>> # irisデータの読み込み
>>> iris = datasets.load_iris()
>>> # 3,4列目の特徴量を抽出
>>> X = iris.data[:, [2,3]]
>>> # クラスラベルの取得
>>> y = iris.target
```

次に、150個のirisデータをトレーニングデータとテストデータに分割する。
ここで、データを分割する理由は、トレーニングしたモデルの性能を評価する際に
未知のデータを使用することで、汎化性能を確かめるためである。

```python
>>> from sklearn.cross_validation import train_test_split
>>> # トレーニングデータとテストデータに分割
>>> # 全体の30%をテストデータとする
>>> X_train, X_test, y_train, y_test = train_test_split(
...     X, y, test_size=0.3, random_state=0)
```

機械学習では特徴量の尺度が同じ場合に性能が向上することが多い、
これについては後で、検証を行う。

```python
>>> from sklearn.preprocessing import StandardScaler
>>> sc = StandardScaler()
>>> # トレーニングデータの平均と標準偏差を計算
>>> sc.fit(X_train)
>>> # 平均と標準偏差を用いて標準化
>>> X_train_std = sc.transform(X_train)
>>> X_test_std = sc.transform(X_test)
```

このコードでは、sklearnのpreprocessingモジュールからStandardScaler
を読み込み、StandardScalerクラスからインスタンスを生成し、scに代入している。
その後、トレーニングデータから特徴量ごとに平均値と標準偏差を計算し、
transformメソッドを呼び出して、標準化を行っている。たとえば、$$j$$番目の特徴量を
標準化するにはサンプル平均$$\mu_j$$をすべてのサンプルデータから引き、
標準偏差$$\sigma_j$$で割れば良い。

$$
\boldsymbol{x}_j'=\frac{\boldsymbol{x_j}-\mu_j}{\sigma_j}
$$
